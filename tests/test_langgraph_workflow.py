"""
===============================================================================
ESSENTRA - Agentic RAG Chatbot
===============================================================================

Author: Tirumala Manav
Email: tirumalamanav@example.com
GitHub: https://github.com/TirumalaManav
LinkedIn: https://linkedin.com/in/tirumalamanav

Project: ESSENTRA - Advanced Agentic RAG Chatbot
Repository: https://github.com/TirumalaManav/essentra-ai
Created: 2025-07-23
Last Modified: 2025-07-23 17:57:58

License: MIT License
Copyright (c) 2025 Tirumala Manav
"""




import asyncio
import sys
import os
from pathlib import Path
import time
import uuid
from datetime import datetime

# Add src to Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

try:
    from langgraph_workflow import LangGraphWorkflow, WorkflowFactory, WorkflowStage
    from agents import AgentManager
    from memory import ConversationMemory, ConversationTurn
    print("‚úÖ Successfully imported LangGraph workflow modules")
except ImportError as e:
    print(f"‚ùå Import error: {e}")
    print("üí° Make sure you have all required dependencies installed:")
    print("   pip install langgraph langchain-core")
    sys.exit(1)

# ==================== MOCK API CLIENTS ====================

class MockGeminiClient:
    """Mock Gemini LLM client for testing"""

    async def generate_response(self, prompt):
        """Mock Gemini response generation"""
        await asyncio.sleep(0.3)  # Simulate API call

        # Analyze prompt to generate realistic responses
        if "artificial intelligence" in prompt.lower():
            return """**Artificial Intelligence (AI)** is a transformative field of computer science that focuses on creating intelligent systems capable of performing tasks that typically require human cognition.

## Key Concepts:

### üß† **Machine Learning**
- **Supervised Learning**: Training models on labeled data
- **Unsupervised Learning**: Finding patterns in unlabeled data
- **Reinforcement Learning**: Learning through rewards and penalties

### üî¨ **Core AI Technologies**
- **Neural Networks**: Inspired by biological brain structure
- **Deep Learning**: Multi-layered neural networks
- **Natural Language Processing**: Understanding and generating human language
- **Computer Vision**: Interpreting visual information

### üöÄ **Applications**
- Autonomous vehicles and robotics
- Healthcare diagnosis and drug discovery
- Financial trading and risk assessment
- Content creation and personalization

AI continues to evolve rapidly, with new breakthroughs in areas like generative models, quantum computing, and AI safety research."""

        elif "machine learning" in prompt.lower():
            return """**Machine Learning (ML)** is a subset of artificial intelligence that enables systems to automatically learn and improve from experience without being explicitly programmed.

## How Machine Learning Works:

### üìä **Data Processing**
1. **Data Collection**: Gathering relevant datasets
2. **Data Preprocessing**: Cleaning and preparing data
3. **Feature Engineering**: Selecting important variables
4. **Model Training**: Teaching algorithms to recognize patterns

### üéØ **Learning Types**
- **Supervised Learning**: Learns from input-output pairs
- **Unsupervised Learning**: Discovers hidden patterns
- **Semi-supervised Learning**: Combines both approaches
- **Reinforcement Learning**: Learns through interaction

### üîß **Popular Algorithms**
- Linear Regression, Decision Trees
- Support Vector Machines (SVM)
- Random Forest, Gradient Boosting
- Neural Networks and Deep Learning

### üìà **Model Evaluation**
- Training, Validation, and Test datasets
- Cross-validation techniques
- Metrics: Accuracy, Precision, Recall, F1-Score"""

        elif "latest" in prompt.lower() or "2025" in prompt.lower():
            return """**Latest AI Developments in 2025** represent significant breakthroughs across multiple domains:

## üöÄ **Major Breakthroughs**

### ü§ñ **Large Language Models**
- Advanced multimodal AI systems
- Improved reasoning and mathematical capabilities
- Better alignment with human values

### üî¨ **Scientific AI**
- AI-driven drug discovery acceleration
- Climate modeling improvements
- Materials science breakthroughs

### üè≠ **Enterprise AI**
-  automation solutions
- Improved AI safety measures
- More efficient training methods

### üåê **AI Governance**
- New regulatory frameworks
- International AI cooperation
- Ethical AI development standards

*Note: This response is based on available training data and general trends.*"""

        else:
            return f"""Based on the provided context and your question, I can offer the following insights:

{prompt[:200]}...

I've analyzed the available information to provide you with a comprehensive response. The key points include relevant details about your topic of interest, supported by the context provided.

For more specific information, please feel free to ask follow-up questions or provide additional context."""

class MockTavilyClient:
    """Mock Tavily web search client for testing"""

    async def search(self, query, max_results=5):
        """Mock web search results"""
        await asyncio.sleep(0.4)  # Simulate API call

        # Generate realistic search results based on query
        results = []

        if "ai" in query.lower() or "artificial intelligence" in query.lower():
            results = [
                {
                    'title': 'Latest AI Research Breakthroughs 2025',
                    'content': 'Recent advances in artificial intelligence include improved large language models, better AI safety measures, and breakthrough applications in healthcare and scientific research.',
                    'url': 'https://ai-research.com/2025-breakthroughs',
                    'score': 0.95
                },
                {
                    'title': 'AI Industry Trends and Market Analysis',
                    'content': 'The AI market continues to grow rapidly with new investments in enterprise AI, autonomous systems, and AI infrastructure development.',
                    'url': 'https://tech-analysis.com/ai-trends-2025',
                    'score': 0.89
                },
                {
                    'title': 'Ethics and AI Development Guidelines',
                    'content': 'New frameworks for responsible AI development focus on transparency, fairness, and human-centered design principles.',
                    'url': 'https://ai-ethics.org/guidelines-2025',
                    'score': 0.85
                }
            ]

        elif "machine learning" in query.lower():
            results = [
                {
                    'title': 'Machine Learning Algorithms Explained',
                    'content': 'Comprehensive guide to supervised, unsupervised, and reinforcement learning techniques with practical examples.',
                    'url': 'https://ml-guide.com/algorithms',
                    'score': 0.92
                },
                {
                    'title': 'Deep Learning Applications in 2025',
                    'content': 'Neural networks and deep learning are revolutionizing computer vision, natural language processing, and predictive analytics.',
                    'url': 'https://deeplearn.net/applications-2025',
                    'score': 0.88
                }
            ]

        else:
            # Generic results for other queries
            results = [
                {
                    'title': f'Search Results for: {query[:30]}...',
                    'content': f'Relevant information about {query} including key concepts, recent developments, and practical applications.',
                    'url': f'https://search-results.com/{query.replace(" ", "-")[:20]}',
                    'score': 0.80
                },
                {
                    'title': f'Expert Analysis: {query[:25]}...',
                    'content': f'In-depth analysis and expert opinions on {query} with current market trends and future predictions.',
                    'url': f'https://expert-analysis.com/{query.replace(" ", "-")[:20]}',
                    'score': 0.75
                }
            ]

        return results[:max_results]

class MockDocumentProcessor:
    """Mock document processor for workflow testing"""

    async def process_document(self, file_path, session_id, **kwargs):
        """Mock document processing"""
        await asyncio.sleep(0.2)

        return type('obj', (object,), {
            'success': True,
            'file_id': str(uuid.uuid4()),
            'chunks_created': 15,
            'processing_time': 1.2,
            'metadata': type('obj', (object,), {
                'dict': lambda: {
                    'file_type': 'pdf',
                    'file_size': 2048000,
                    'filename': file_path.split('/')[-1] if '/' in file_path else file_path,
                    'session_id': session_id
                }
            })()
        })()

    async def retrieve_similar_chunks(self, query, session_id, n_results=5):
        """Mock semantic retrieval"""
        await asyncio.sleep(0.1)

        # Generate contextual chunks based on query
        chunks = []

        if "artificial intelligence" in query.lower():
            chunks = [
                {
                    'content': 'Artificial intelligence represents a paradigm shift in computing, enabling machines to perform cognitive tasks traditionally requiring human intelligence.',
                    'metadata': {'source_file': 'ai_textbook.pdf', 'chunk_index': 0, 'file_id': str(uuid.uuid4())},
                    'similarity_score': 0.92
                },
                {
                    'content': 'Machine learning algorithms form the backbone of modern AI systems, utilizing statistical methods to identify patterns in large datasets.',
                    'metadata': {'source_file': 'ml_handbook.pdf', 'chunk_index': 1, 'file_id': str(uuid.uuid4())},
                    'similarity_score': 0.88
                }
            ]

        elif "machine learning" in query.lower():
            chunks = [
                {
                    'content': 'Supervised learning algorithms learn from labeled training data to make predictions on new, unseen data points.',
                    'metadata': {'source_file': 'ml_fundamentals.pdf', 'chunk_index': 0, 'file_id': str(uuid.uuid4())},
                    'similarity_score': 0.90
                },
                {
                    'content': 'Neural networks consist of interconnected nodes that process information through weighted connections, mimicking brain functionality.',
                    'metadata': {'source_file': 'neural_networks.pdf', 'chunk_index': 2, 'file_id': str(uuid.uuid4())},
                    'similarity_score': 0.85
                }
            ]

        else:
            # Generic chunks for other queries
            chunks = [
                {
                    'content': f'This document section discusses key aspects of {query[:30]}... providing comprehensive insights and detailed analysis.',
                    'metadata': {'source_file': 'reference_document.pdf', 'chunk_index': 0, 'file_id': str(uuid.uuid4())},
                    'similarity_score': 0.75
                }
            ]

        return chunks[:n_results]

# ==================== WORKFLOW TESTER ====================

class LangGraphWorkflowTester:
    """Comprehensive LangGraph workflow tester"""

    def __init__(self):
        self.test_results = []
        self.session_id = f"test_session_MANAV_{int(time.time())}"
        self.workflow = None

        print(f"üß™ Initialized LangGraph workflow tester")
        print(f"üë§ User: TIRUMALAMANAV")
        print(f"üÜî Session: {self.session_id}")

    async def setup_test_environment(self):
        """Setup test environment with mock clients"""
        print("üîß Setting up LangGraph test environment...")

        try:
            # Create mock clients
            mock_llm = MockGeminiClient()
            mock_web = MockTavilyClient()
            mock_processor = MockDocumentProcessor()

            # Create workflow with mocks
            self.workflow = WorkflowFactory.create_production_workflow(
                document_processor=mock_processor,
                llm_client=mock_llm,
                web_search_client=mock_web
            )

            print("‚úÖ LangGraph workflow created with mock APIs")
            print("üí° No real API calls will be made (saving costs!)")

            return True

        except Exception as e:
            print(f"‚ùå Setup failed: {str(e)}")
            return False

    async def test_document_based_query(self):
        """Test document-based query workflow"""
        print("\nüìÑ Testing Document-Based Query Workflow...")

        query = "What is artificial intelligence and how does machine learning work?"
        print(f"  üìù Query: '{query}'")

        try:
            start_time = time.time()
            result = await self.workflow.process_user_request(query, self.session_id)
            end_time = time.time()

            processing_time = end_time - start_time

            # Validate results
            success = result['success']
            response_length = len(result['response'])
            confidence = result['confidence']
            sources_count = len(result['sources'])

            print(f"    ‚úÖ Success: {success}")
            print(f"    ‚è±Ô∏è Processing time: {processing_time:.2f}s")
            print(f"    üìè Response length: {response_length} chars")
            print(f"    üéØ Confidence: {confidence:.1%}")
            print(f"    üìö Sources found: {sources_count}")

            # Check workflow metadata
            metadata = result.get('workflow_metadata', {})
            print(f"    üîç Detected intent: {metadata.get('detected_intent', 'unknown')}")
            print(f"    üîÑ Routing decision: {metadata.get('routing_decision', 'unknown')}")

            # Validate response quality
            if success and response_length > 100 and confidence > 0.5:
                print(f"    üéâ Document workflow: PASSED")
                test_passed = True
            else:
                print(f"    ‚ùå Document workflow: FAILED")
                test_passed = False

            self.test_results.append({
                'test': 'document_based_query',
                'passed': test_passed,
                'processing_time': processing_time,
                'confidence': confidence,
                'metadata': metadata
            })

            # Show sample response (first 200 chars)
            print(f"    üìñ Response preview: {result['response'][:200]}...")

            return test_passed

        except Exception as e:
            print(f"    ‚ùå Document workflow error: {str(e)}")
            self.test_results.append({
                'test': 'document_based_query',
                'passed': False,
                'error': str(e)
            })
            return False

    async def test_web_search_query(self):
        """Test web search query workflow"""
        print("\nüåê Testing Web Search Query Workflow...")

        query = "What are the latest AI developments and breakthroughs in 2025?"
        print(f"  üìù Query: '{query}'")

        try:
            start_time = time.time()
            result = await self.workflow.process_user_request(query, self.session_id)
            end_time = time.time()

            processing_time = end_time - start_time

            # Validate results
            success = result['success']
            response_length = len(result['response'])
            confidence = result['confidence']
            sources_count = len(result['sources'])

            print(f"    ‚úÖ Success: {success}")
            print(f"    ‚è±Ô∏è Processing time: {processing_time:.2f}s")
            print(f"    üìè Response length: {response_length} chars")
            print(f"    üéØ Confidence: {confidence:.1%}")
            print(f"    üåê Web sources: {sources_count}")

            # Check workflow metadata
            metadata = result.get('workflow_metadata', {})
            print(f"    üîç Detected intent: {metadata.get('detected_intent', 'unknown')}")
            print(f"    üîÑ Routing decision: {metadata.get('routing_decision', 'unknown')}")

            # Validate web search workflow
            web_results_count = metadata.get('web_results_count', 0)
            print(f"    üåê Web results found: {web_results_count}")

            if success and response_length > 100 and web_results_count >= 0:
                print(f"    üéâ Web search workflow: PASSED")
                test_passed = True
            else:
                print(f"    ‚ùå Web search workflow: FAILED")
                test_passed = False

            self.test_results.append({
                'test': 'web_search_query',
                'passed': test_passed,
                'processing_time': processing_time,
                'confidence': confidence,
                'metadata': metadata
            })

            # Show sample response (first 200 chars)
            print(f"    üìñ Response preview: {result['response'][:200]}...")

            return test_passed

        except Exception as e:
            print(f"    ‚ùå Web search workflow error: {str(e)}")
            self.test_results.append({
                'test': 'web_search_query',
                'passed': False,
                'error': str(e)
            })
            return False

    async def test_conversation_memory(self):
        """Test conversation memory functionality"""
        print("\nüß† Testing Conversation Memory...")

        # First query
        query1 = "What is machine learning?"
        print(f"  üìù Query 1: '{query1}'")

        try:
            result1 = await self.workflow.process_user_request(query1, self.session_id)

            if result1['success']:
                print(f"    ‚úÖ First query processed successfully")

                # Second query (should have memory context)
                query2 = "Can you explain more about the algorithms you mentioned?"
                print(f"  üìù Query 2: '{query2}'")

                result2 = await self.workflow.process_user_request(query2, self.session_id)

                if result2['success']:
                    print(f"    ‚úÖ Second query with memory context: PASSED")

                    # Check if memory was updated
                    memory_updated = result2.get('workflow_metadata', {}).get('memory_updated', False)
                    print(f"    üß† Memory updated: {memory_updated}")

                    test_passed = True
                else:
                    print(f"    ‚ùå Second query failed")
                    test_passed = False
            else:
                print(f"    ‚ùå First query failed")
                test_passed = False

            self.test_results.append({
                'test': 'conversation_memory',
                'passed': test_passed
            })

            return test_passed

        except Exception as e:
            print(f"    ‚ùå Memory test error: {str(e)}")
            self.test_results.append({
                'test': 'conversation_memory',
                'passed': False,
                'error': str(e)
            })
            return False

    async def test_error_handling(self):
        """Test workflow error handling"""
        print("\n‚ö†Ô∏è Testing Error Handling...")

        # Test with empty query
        empty_query = ""
        print(f"  üìù Testing empty query...")

        try:
            result = await self.workflow.process_user_request(empty_query, self.session_id)

            # Should handle gracefully
            if result['success'] or len(result['response']) > 0:
                print(f"    ‚úÖ Empty query handled gracefully")
                error_test_passed = True
            else:
                print(f"    ‚ùå Empty query not handled properly")
                error_test_passed = False

            self.test_results.append({
                'test': 'error_handling',
                'passed': error_test_passed
            })

            return error_test_passed

        except Exception as e:
            print(f"    ‚ùå Error handling test failed: {str(e)}")
            self.test_results.append({
                'test': 'error_handling',
                'passed': False,
                'error': str(e)
            })
            return False

    def print_summary(self):
        """Print comprehensive test summary"""
        print("\n" + "="*70)
        print("üìã LANGGRAPH WORKFLOW TEST SUMMARY")
        print("="*70)
        print(f"üë§ User: TIRUMALAMANAV")
        print(f"‚è∞ Time: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üÜî Session: {self.session_id}")
        print(f"üìÖ Date: 2025-07-22 13:35:34 UTC")

        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results if result['passed'])

        print(f"\nüìä OVERALL RESULTS:")
        print(f"Total tests: {total_tests}")
        print(f"Passed: {passed_tests}")
        print(f"Failed: {total_tests - passed_tests}")
        print(f"Success rate: {(passed_tests/total_tests)*100:.1f}%")

        print(f"\nüìã DETAILED RESULTS:")
        for result in self.test_results:
            status = "‚úÖ PASS" if result['passed'] else "‚ùå FAIL"
            test_name = result['test'].replace('_', ' ').title()
            print(f"  {status} - {test_name}")

            if 'processing_time' in result:
                print(f"    ‚è±Ô∏è Processing time: {result['processing_time']:.2f}s")
            if 'confidence' in result:
                print(f"    üéØ Confidence: {result['confidence']:.1%}")
            if 'error' in result:
                print(f"    ‚ùå Error: {result['error']}")

        print("\n" + "="*70)

        if passed_tests == total_tests:
            print("üéâ ALL LANGGRAPH WORKFLOW TESTS PASSED!")
        else:
            print("‚ö†Ô∏è Some tests failed. Please review the issues.")
            print("üí° System is functional but needs refinement.")

async def main():
    """Main test runner for LangGraph workflow"""
    print("üß™ LANGGRAPH WORKFLOW TEST SUITE")
    print(f"üë§ User: TIRUMALAMANAV")
    print(f"üìÖ Current Date: 2025-07-22 13:35:34 UTC")
    print("üéØ Testing complete workflow with mock APIs")
    print("=" * 70)

    tester = LangGraphWorkflowTester()

    try:
        # Setup test environment
        setup_success = await tester.setup_test_environment()

        if not setup_success:
            print("‚ùå Test setup failed. Exiting.")
            return

        # Run all tests
        tests = [
            tester.test_document_based_query(),
            tester.test_web_search_query(),
            tester.test_conversation_memory(),
            tester.test_error_handling()
        ]

        print(f"\nüöÄ Running {len(tests)} comprehensive workflow tests...")

        for i, test in enumerate(tests, 1):
            print(f"\nüîÑ Running workflow test {i}/{len(tests)}...")
            await test
            await asyncio.sleep(0.2)  # Brief pause between tests

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Tests interrupted by user")
    except Exception as e:
        print(f"\nüí• Test suite error: {e}")
        import traceback
        traceback.print_exc()

    finally:
        tester.print_summary()

if __name__ == "__main__":
    # Ensure proper environment
    if not os.path.exists("src"):
        print("‚ùå Please run this test from the project root directory")
        print("   Current directory should contain 'src' folder")
        sys.exit(1)

    # Run the LangGraph workflow test suite
    asyncio.run(main())
